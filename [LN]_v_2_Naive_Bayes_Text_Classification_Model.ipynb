{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenliliana/text-classification-model-pytorch/blob/main/%5BLN%5D_v_2_Naive_Bayes_Text_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Guo4Jo8vOo_",
        "outputId": "a9975b01-f8a3-49de-f779-7cea3c0542ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 8.1 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 1.2 MB/s eta 0:00:44tcmalloc: large alloc 1147494400 bytes == 0x3a794000 @  0x7f8d72b54615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 887.4 MB 1.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.23.0)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.4.0)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 26 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 72.1 MB/s \n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 11 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchdata) (57.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchdata) (0.38.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 83.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Installing collected packages: nvidia-cublas-cu11, urllib3, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 portalocker-2.6.0 torch-1.13.1 torchdata-0.5.1 urllib3-1.25.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.14.1-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchtext) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext) (4.64.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchtext) (11.7.99)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchtext) (4.4.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchtext) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchtext) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchtext) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchtext) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchtext) (57.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.0\n",
            "    Uninstalling torchtext-0.14.0:\n",
            "      Successfully uninstalled torchtext-0.14.0\n",
            "Successfully installed torchtext-0.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata\n",
        "!pip install -U torchtext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVlqjhKifPgD"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM335uUIvbxy",
        "outputId": "12f1dcf8-b2a7-4b6c-a12f-1084c91f3f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56006\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.datasets import AG_NEWS\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from string import punctuation\n",
        "\n",
        "train_iter = iter(AG_NEWS(split='train'))\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def strip_punctuation(s):\n",
        "    return ''.join(c for c in s if c not in punctuation)\n",
        "def clean_text(text): \n",
        "  clean = text.lower()\n",
        "  clean = clean.replace(\".\", \" \")\n",
        "  clean = clean.replace(\"\\\\\", \" \")\n",
        "  clean = clean.replace(\"-\", \" \")\n",
        "  clean = clean.replace(\"'\", \" \")\n",
        "  clean = clean.replace(\":\", \" \")\n",
        "  clean = clean.replace(\"#\", \" \")\n",
        "  clean = clean.replace(\"$\", \" \")\n",
        "  clean = clean.replace(\",\", \" \")\n",
        "  clean = clean.replace(\"1\", \" \")\n",
        "  clean = clean.replace(\"2\", \" \")\n",
        "  clean = clean.replace(\"3\", \" \")\n",
        "  clean = clean.replace(\"4\", \" \")\n",
        "  clean = clean.replace(\"5\", \" \")\n",
        "  clean = clean.replace(\"6\", \" \")\n",
        "  clean = clean.replace(\"7\", \" \")\n",
        "  clean = clean.replace(\"8\", \" \")\n",
        "  clean = clean.replace(\"9\", \" \")\n",
        "  clean = clean.replace(\"0\", \" \")\n",
        "  clean = clean.replace(\"(\", \" \")\n",
        "  clean = clean.replace(\")\", \" \")\n",
        "  clean = strip_punctuation(clean)\n",
        "  clean = remove_stopwords(clean)\n",
        "  return clean\n",
        "  \n",
        "training_size = 84000 #70%\n",
        "\n",
        "#BUILD VOCAB WITH TRAINING DATA\n",
        "def yield_tokens(data_iter): \n",
        "  count = 0\n",
        "  for label, text in data_iter: \n",
        "    if count == training_size:\n",
        "      break; \n",
        "    count += 1\n",
        "    yield tokenizer(clean_text(text))\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"]) #when out of vocab token is queried, return index of <unk>\n",
        "\n",
        "print(len(vocab))\n",
        "# print(vocab.get_itos())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXNg5gR6fT-G"
      },
      "source": [
        "# Make Training and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D50mDJKVzIfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a546109d-f420-45ae-b825-2b56db6e0ab4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120000\n",
            "120000\n"
          ]
        }
      ],
      "source": [
        "#MAKE TRAINING AND TESTING SETS\n",
        "train_iter = iter(AG_NEWS(split='train'))\n",
        "text_list = []\n",
        "label_list = []\n",
        "for label, text in train_iter:\n",
        "  text_list.append(tokenizer(clean_text(text)))\n",
        "  label_list.append(label)\n",
        "\n",
        "print(len(text_list))\n",
        "print(len(label_list))\n",
        "\n",
        "train_list = text_list[0:training_size]\n",
        "train_label = label_list[0:training_size]\n",
        "test_list = text_list[training_size:120001]\n",
        "test_label = label_list[training_size:120001]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKJjV7cAfYoJ"
      },
      "source": [
        "# Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvolZ1gZ1OVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658e03e2-8586-4e52-d1c7-7486e9e109a9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['venezuelans', 'vote', 'early', 'referendum', 'chavez', 'rule', 'reuters', 'reuters', 'venezuelans', 'turned', 'early', 'large', 'numbers', 'sunday', 'vote', 'historic', 'referendum', 'remove', 'left', 'wing']\n",
            "['phelps', 'thorpe', 'advance', 'freestyle', 'ap', 'ap', 'michael', 'phelps', 'took', 'care', 'qualifying', 'olympic', 'meter', 'freestyle', 'semifinals', 'sunday', 'added', 'american', 'team', 'evening']\n",
            "['wall', 'st', 'bears', 'claw', 'black', 'reuters', 'reuters', 'short', 'sellers', 'wall', 'street', 's', 'dwindling', 'band', 'ultra', 'cynics', 'seeing', 'green', 'carlyle', 'looks']\n",
            "['madden', 'espn', 'football', 'score', 'different', 'ways', 'reuters', 'reuters', 'absenteeism', 'little', 'high', 'tuesday', 'guys', 'office', 'ea', 'sports', 'like', 'think', 'madden', 'nfl']\n"
          ]
        }
      ],
      "source": [
        "#MAKE BOWs\n",
        "\n",
        "#sort training data by label\n",
        "\n",
        "labels_set = set(train_label)\n",
        "\n",
        "sorted_docs = {}\n",
        "for i in labels_set: \n",
        "  sorted_docs[i] = []\n",
        "\n",
        "\n",
        "for i in range(len(train_list)): \n",
        "    sorted_docs[train_label[i]] += train_list[i]\n",
        "\n",
        "# print(sorted_docs[1][0:20])\n",
        "# print(sorted_docs[2][0:20])\n",
        "# print(sorted_docs[3][0:20])\n",
        "# print(sorted_docs[4][0:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5574wPZ7PIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a76702a8-c82f-4ec0-ec33-805028f04f58"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7064a8d2-8da0-4477-b523-3055603fd09a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>55996</th>\n",
              "      <th>55997</th>\n",
              "      <th>55998</th>\n",
              "      <th>55999</th>\n",
              "      <th>56000</th>\n",
              "      <th>56001</th>\n",
              "      <th>56002</th>\n",
              "      <th>56003</th>\n",
              "      <th>56004</th>\n",
              "      <th>56005</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>12500</td>\n",
              "      <td>2545</td>\n",
              "      <td>5507</td>\n",
              "      <td>3827</td>\n",
              "      <td>3979</td>\n",
              "      <td>1091</td>\n",
              "      <td>2523</td>\n",
              "      <td>912</td>\n",
              "      <td>864</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10477</td>\n",
              "      <td>2744</td>\n",
              "      <td>1043</td>\n",
              "      <td>1306</td>\n",
              "      <td>4121</td>\n",
              "      <td>1721</td>\n",
              "      <td>516</td>\n",
              "      <td>2310</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>11496</td>\n",
              "      <td>4714</td>\n",
              "      <td>5068</td>\n",
              "      <td>6129</td>\n",
              "      <td>313</td>\n",
              "      <td>2144</td>\n",
              "      <td>2298</td>\n",
              "      <td>1520</td>\n",
              "      <td>4873</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>9614</td>\n",
              "      <td>5125</td>\n",
              "      <td>2609</td>\n",
              "      <td>2318</td>\n",
              "      <td>2717</td>\n",
              "      <td>1494</td>\n",
              "      <td>1007</td>\n",
              "      <td>1426</td>\n",
              "      <td>74</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 56006 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7064a8d2-8da0-4477-b523-3055603fd09a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7064a8d2-8da0-4477-b523-3055603fd09a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7064a8d2-8da0-4477-b523-3055603fd09a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
              "0      1  12500   2545   5507   3827   3979   1091   2523    912    864  ...   \n",
              "1      1  10477   2744   1043   1306   4121   1721    516   2310      3  ...   \n",
              "2      1  11496   4714   5068   6129    313   2144   2298   1520   4873  ...   \n",
              "3      1   9614   5125   2609   2318   2717   1494   1007   1426     74  ...   \n",
              "\n",
              "   55996  55997  55998  55999  56000  56001  56002  56003  56004  56005  \n",
              "0      1      1      1      1      1      1      1      1      1      1  \n",
              "1      1      2      1      1      2      1      2      1      1      2  \n",
              "2      1      1      2      1      1      1      1      2      1      1  \n",
              "3      2      1      1      2      1      2      1      1      2      1  \n",
              "\n",
              "[4 rows x 56006 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "#find tf for each label\n",
        "\n",
        "def calculateBOW(doc): \n",
        "  tf_diz = dict.fromkeys([i for i in range(len(vocab))],1)\n",
        "  for word in doc: \n",
        "    tf_diz[vocab[word]] += 1; \n",
        "  return tf_diz\n",
        "\n",
        "bows = dict.fromkeys([i for i in labels_set],{})\n",
        "\n",
        "for i in labels_set: \n",
        "  bows[i] = calculateBOW(sorted_docs[i])\n",
        "\n",
        "df_bow = pd.DataFrame([bows[1],bows[2], bows[3] ,bows[4]])\n",
        "df_bow.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smdZ7zRGfjq_"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrLOKvKP-68p"
      },
      "outputs": [],
      "source": [
        "#NAIVE BAYES\n",
        "total_bow_size = 0\n",
        "# for i in labels_set: \n",
        "   #total_bow_size += len(bows[i])\n",
        "total_bow_size = len(train_label)\n",
        "#P(label|words) = P(label) * P(word1|label) * P(word2|label) * ...\n",
        "def NB(sentence):\n",
        "    NB_vals = []\n",
        "    for i in labels_set: \n",
        "      # p = len(bows[i])/total_bow_size\n",
        "      p = train_label.count(i)/total_bow_size\n",
        "      for word in sentence: \n",
        "        \n",
        "        p *= ((bows[i])[vocab[word]])/len(bows[i])\n",
        "      NB_vals.append(p)\n",
        "    max_value = max(NB_vals)\n",
        "    max_index = NB_vals.index(max_value)\n",
        "    return max_index+1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok-pyK8ffolc"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIoVvcQPvHMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01907195-41c3-4513-8915-1c777574affa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8961944444444444\n"
          ]
        }
      ],
      "source": [
        "#TEST\n",
        "def accuracy(text, label):\n",
        "  correct = 0\n",
        "  for i in range(len(text)):\n",
        "    if(NB(text[i]) == label[i]):\n",
        "      correct += 1\n",
        "  return correct / len(text)\n",
        "print(accuracy(test_list, test_label))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNp4BTSdjHyCl6kQEeUEPql",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}